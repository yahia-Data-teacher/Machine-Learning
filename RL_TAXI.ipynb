{"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "markdown", "metadata": {"id": "view-in-github", "colab_type": "text"}, "source": ["<a href=\"https://colab.research.google.com/github/yahia-kplr/Machine-Learning/blob/main/RL_TAXI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "kAonI6zEo-AE", "outputId": "5e0c1123-d0d0-47c2-ffdf-b9d0de20d5b8"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n", "Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (3.22.5)\n", "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n", "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n", "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n", "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.5.0)\n", "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.3.0)\n", "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (0.2.9)\n", "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (7.1.2)\n", "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (4.6.0.66)\n", "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari]) (1.15.0)\n", "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n"]}], "source": ["!pip install cmake 'gym[atari]' scipy"]}, {"cell_type": "code", "source": ["import gym\n", "\n", "env = gym.make(\"Taxi-v3\").env\n", "\n", "env.render()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4GPG5Hs7o-wV", "outputId": "5632cf83-1690-4bff-ffd8-a02719cee921"}, "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["+---------+\n", "|R: | : :\u001b[34;1mG\u001b[0m|\n", "| : | : : |\n", "| : : : : |\n", "| | :\u001b[43m \u001b[0m| : |\n", "|\u001b[35mY\u001b[0m| : |B: |\n", "+---------+\n", "\n"]}]}, {"cell_type": "code", "source": ["env.reset() # reset environment to a new, random state\n", "env.render()\n", "\n", "print(\"Action Space {}\".format(env.action_space))\n", "print(\"State Space {}\".format(env.observation_space))"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "5tsuSraApBZv", "outputId": "fd18efaf-4301-4d58-dd1b-dc111b4228c8"}, "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["+---------+\n", "|\u001b[35mR\u001b[0m: | : :G|\n", "| : | : : |\n", "| : : : : |\n", "| | :\u001b[43m \u001b[0m| : |\n", "|Y| : |\u001b[34;1mB\u001b[0m: |\n", "+---------+\n", "\n", "Action Space Discrete(6)\n", "State Space Discrete(500)\n"]}]}, {"cell_type": "code", "source": ["state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n", "print(\"State:\", state)\n", "\n", "env.s = state\n", "env.render()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qEbAz-Y9pbHw", "outputId": "de06ef46-53d8-48d4-88b9-1540fb9c6f03"}, "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["State: 328\n", "+---------+\n", "|\u001b[35mR\u001b[0m: | : :G|\n", "| : | : : |\n", "| : : : : |\n", "| |\u001b[43m \u001b[0m: | : |\n", "|\u001b[34;1mY\u001b[0m| : |B: |\n", "+---------+\n", "\n"]}]}, {"cell_type": "code", "source": ["env.P[328]"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "VQM0jO-iponz", "outputId": "9b210bd8-4804-46ae-abcf-afeb85872a30"}, "execution_count": 7, "outputs": [{"output_type": "execute_result", "data": {"text/plain": ["{0: [(1.0, 428, -1, False)],\n", " 1: [(1.0, 228, -1, False)],\n", " 2: [(1.0, 348, -1, False)],\n", " 3: [(1.0, 328, -1, False)],\n", " 4: [(1.0, 328, -10, False)],\n", " 5: [(1.0, 328, -10, False)]}"]}, "metadata": {}, "execution_count": 7}]}, {"cell_type": "code", "source": ["env.s = 328  # set environment to illustration's state\n", "\n", "epochs = 0\n", "penalties, reward = 0, 0\n", "\n", "frames = [] # for animation\n", "\n", "done = False\n", "\n", "while not done:\n", "    action = env.action_space.sample()\n", "    state, reward, done, info = env.step(action)\n", "\n", "    if reward == -10:\n", "        penalties += 1\n", "    \n", "    # Put each rendered frame into dict for animation\n", "    frames.append({\n", "        'frame': env.render(mode='ansi'),\n", "        'state': state,\n", "        'action': action,\n", "        'reward': reward\n", "        }\n", "    )\n", "\n", "    epochs += 1\n", "    \n", "    \n", "print(\"Timesteps taken: {}\".format(epochs))\n", "print(\"Penalties incurred: {}\".format(penalties))"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "VI0kiKoPpssJ", "outputId": "4d8790bf-683b-42e7-9472-de5d75dbf553"}, "execution_count": 8, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Timesteps taken: 12586\n", "Penalties incurred: 4188\n"]}]}, {"cell_type": "code", "source": ["from IPython.display import clear_output\n", "from time import sleep\n", "\n", "def print_frames(frames):\n", "    for i, frame in enumerate(frames):\n", "        clear_output(wait=True)\n", "        print(frame['frame'])\n", "        print(f\"Timestep: {i + 1}\")\n", "        print(f\"State: {frame['state']}\")\n", "        print(f\"Action: {frame['action']}\")\n", "        print(f\"Reward: {frame['reward']}\")\n", "        sleep(.1)\n", "        \n", "print_frames(frames)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 548}, "id": "_v9kf-lsp0B7", "outputId": "48d5edad-9ce6-4f64-e5bb-49599a63afa2"}, "execution_count": 11, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["+---------+\n", "|\u001b[35mR\u001b[0m: | :\u001b[42m_\u001b[0m:G|\n", "| : | : : |\n", "| : : : : |\n", "| | : | : |\n", "|Y| : |B: |\n", "+---------+\n", "  (North)\n", "\n", "Timestep: 6325\n", "State: 76\n", "Action: 1\n", "Reward: -1\n"]}, {"output_type": "error", "ename": "KeyboardInterrupt", "evalue": "ignored", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-11-adcf58a03b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m<ipython-input-11-adcf58a03b7e>\u001b[0m in \u001b[0;36mprint_frames\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Action: {frame['action']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reward: {frame['reward']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}, {"cell_type": "code", "source": ["import numpy as np\n", "q_table = np.zeros([env.observation_space.n, env.action_space.n])"], "metadata": {"id": "U_6AWTSop81t"}, "execution_count": 12, "outputs": []}, {"cell_type": "code", "source": ["%%time\n", "\"\"\"Training the agent\"\"\"\n", "\n", "import random\n", "from IPython.display import clear_output\n", "\n", "# Hyperparameters\n", "alpha = 0.1\n", "gamma = 0.6\n", "epsilon = 0.1\n", "\n", "# For plotting metrics\n", "all_epochs = []\n", "all_penalties = []\n", "\n", "for i in range(1, 100001):\n", "    state = env.reset()\n", "\n", "    epochs, penalties, reward, = 0, 0, 0\n", "    done = False\n", "    \n", "    while not done:\n", "        if random.uniform(0, 1) < epsilon:\n", "            action = env.action_space.sample() # Explore action space\n", "        else:\n", "            action = np.argmax(q_table[state]) # Exploit learned values\n", "\n", "        next_state, reward, done, info = env.step(action) \n", "        \n", "        old_value = q_table[state, action]\n", "        next_max = np.max(q_table[next_state])\n", "        \n", "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n", "        q_table[state, action] = new_value\n", "\n", "        if reward == -10:\n", "            penalties += 1\n", "\n", "        state = next_state\n", "        epochs += 1\n", "        \n", "    if i % 100 == 0:\n", "        clear_output(wait=True)\n", "        print(f\"Episode: {i}\")\n", "\n", "print(\"Training finished.\\n\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "_3LP-wwVqmBD", "outputId": "3bf12a23-a833-4b38-afa4-c19070da8349"}, "execution_count": 13, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Episode: 100000\n", "Training finished.\n", "\n", "CPU times: user 57.5 s, sys: 9.18 s, total: 1min 6s\n", "Wall time: 59.3 s\n"]}]}, {"cell_type": "code", "source": ["q_table[328]"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ze0tmkbLqvRJ", "outputId": "109b43a0-6d0a-4173-ff50-c0d87d919584"}, "execution_count": 14, "outputs": [{"output_type": "execute_result", "data": {"text/plain": ["array([ -2.41180637,  -2.27325184,  -2.40716064,  -2.35972746,\n", "       -10.43230522, -10.2118609 ])"]}, "metadata": {}, "execution_count": 14}]}, {"cell_type": "code", "source": ["\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n", "\n", "total_epochs, total_penalties = 0, 0\n", "episodes = 100\n", "\n", "for _ in range(episodes):\n", "    state = env.reset()\n", "    epochs, penalties, reward = 0, 0, 0\n", "    \n", "    done = False\n", "    \n", "    while not done:\n", "        action = np.argmax(q_table[state])\n", "        state, reward, done, info = env.step(action)\n", "\n", "        if reward == -10:\n", "            penalties += 1\n", "\n", "        epochs += 1\n", "\n", "    total_penalties += penalties\n", "    total_epochs += epochs\n", "\n", "print(f\"Results after {episodes} episodes:\")\n", "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n", "print(f\"Average penalties per episode: {total_penalties / episodes}\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ixariknuqv6J", "outputId": "ef71ed8e-b557-489f-ed6d-c2b16e8fcda6"}, "execution_count": 15, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Results after 100 episodes:\n", "Average timesteps per episode: 12.53\n", "Average penalties per episode: 0.0\n"]}]}, {"cell_type": "code", "source": [""], "metadata": {"id": "Z1DXvwNXq9hO"}, "execution_count": 15, "outputs": []}]}